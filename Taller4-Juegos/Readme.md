# Taller 4 - Implementaci√≥n del Algoritmo MINIMAX para Triqui
**Inteligencia Artificial - Juegos Multijugador**  
**Pontificia Universidad Javeriana - Bogot√°**  
**Departamento de Ingenier√≠a de Sistemas**

---

## üìö Informaci√≥n del Proyecto

- **Curso**: Inteligencia Artificial
- **Profesor**: Ing. Laura Juliana Mora P√°ez Msc
- **Tema**: Juegos Multijugador - Algoritmo MINIMAX
- **Grupo**: [5]
- **Integrantes**: 
- Alejandra Abaunza Su√°rez 
- Daniel Santiago Avila Medina
- Santos Alejandro Arellano Olarte
- Jeison Camilo Alfonso Moreno


---

## üéØ Objetivo del Taller

Implementar el algoritmo MINIMAX para el juego de Triqui (Tic-Tac-Toe) en un tablero 3x3, donde dos jugadores se alternan para colocar s√≠mbolos 'X' y 'O', ganando quien logre poner tres en l√≠nea.

---

## üìã Requisitos Implementados

### 1. **Representaci√≥n del Estado** ‚úÖ

El estado del juego se representa mediante una **matriz 3x3** donde:

```python
# Estado inicial (tablero vac√≠o)
board = [[0, 0, 0],
         [0, 0, 0],
         [0, 0, 0]]

# Valores posibles:
# 0 = Casilla vac√≠a
# 1 = X (Jugador MAX - Humano)
# -1 = O (Jugador MIN - IA)
```

**Justificaci√≥n de la representaci√≥n:**
- Uso de valores num√©ricos (1, -1, 0) facilita el c√°lculo de la funci√≥n heur√≠stica
- La representaci√≥n matricial permite acceso directo O(1) a cualquier posici√≥n
- Los valores 1 y -1 simplifican la alternancia de turnos y evaluaci√≥n de estados

### 2. **Funci√≥n Heur√≠stica** ‚úÖ

La funci√≥n `evaluate_state()` implementa una evaluaci√≥n sofisticada basada en m√∫ltiples indicadores:

#### **Indicadores utilizados:**

1. **Ind1 - Estados Terminales**:
   - Victoria de X (MAX): **+1000 puntos**
   - Victoria de O (MIN): **-1000 puntos**
   - Empate: **0 puntos**

2. **Ind2 - L√≠neas Potenciales**:
   - L√≠nea con 2X y sin O: **+50 puntos** (casi victoria para MAX)
   - L√≠nea con 1X y sin O: **+10 puntos** (potencial para MAX)
   - L√≠nea con 2O y sin X: **-50 puntos** (peligro, debe bloquearse)
   - L√≠nea con 1O y sin X: **-10 puntos** (potencial para MIN)

3. **Ind3 - Control Posicional**:
   - Control del centro (1,1): **¬±30 puntos**
   - Control de esquinas: **¬±15 puntos** cada una

#### **F√≥rmula de la Funci√≥n Heur√≠stica:**

```
H(estado) = w1√ó(Victoria) + w2√ó(L√≠neas_Potenciales) + w3√ó(Control_Posicional)

Donde:
- w1 = 1000 (peso m√°ximo para estados terminales)
- w2 = Variable seg√∫n el tipo de l√≠nea (50, 10)
- w3 = Variable seg√∫n la posici√≥n (30 centro, 15 esquinas)
```

### 3. **Generaci√≥n de Sucesores** ‚úÖ

La funci√≥n `get_valid_moves()` genera todos los movimientos v√°lidos (sucesores) de un estado:

```python
def get_valid_moves(state):
    # Retorna lista de tuplas (fila, columna) 
    # donde hay casillas vac√≠as (valor = 0)
    moves = []
    for i in range(3):
        for j in range(3):
            if state[i][j] == 0:
                moves.append((i, j))
    return moves
```

**Caracter√≠sticas:**
- Exploraci√≥n completa del espacio de estados
- Generaci√≥n din√°mica seg√∫n el estado actual
- Complejidad O(9) en el peor caso

### 4. **Efectuar Jugadas y Dar Turno** ‚úÖ

El sistema implementa:

- **Alternancia autom√°tica de turnos** entre humano y IA
- **Validaci√≥n de movimientos** (casilla vac√≠a, dentro del tablero)
- **Interfaz interactiva** para entrada del usuario
- **Retroalimentaci√≥n visual** del estado del tablero

### 5. **BONUS: Poda Alfa-Beta** ‚≠ê ‚úÖ

Implementaci√≥n completa de la optimizaci√≥n Alfa-Beta:

```python
def minimax(state, depth, is_maximizing, alpha=-‚àû, beta=+‚àû):
    # Poda cuando beta <= alpha
    # Reduce el espacio de b√∫squeda significativamente
```

**Mejoras de la Poda Alfa-Beta:**
- Reduce el n√∫mero de nodos evaluados de O(b^d) a O(b^(d/2)) en el mejor caso
- Mantiene la optimalidad del resultado
- Mejora significativa en tiempo de respuesta

---

## üéÆ Funcionamiento del Algoritmo MINIMAX

### √Årbol de Juego

```
                    Estado_Inicial
                    (Tablero vac√≠o)
                         |
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            |            |            |
         MAX(X)       MAX(X)       MAX(X)    ... (9 opciones)
            |            |            |
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       |    |    |  |    |    |  |    |    |
    MIN(O) MIN  MIN MIN  MIN MIN MIN  MIN MIN  ... (8 opciones c/u)
       |                                    
    (recursi√≥n hasta estado terminal)
```

### Proceso de Decisi√≥n

1. **MAX (Jugador X)** busca maximizar la evaluaci√≥n
2. **MIN (Jugador O)** busca minimizar la evaluaci√≥n
3. Se eval√∫an recursivamente todos los estados posibles
4. Se propaga el mejor valor hacia arriba en el √°rbol
5. La ra√≠z selecciona el movimiento con mejor evaluaci√≥n

---

## üíª Instrucciones de Uso

### Requisitos del Sistema
- Python 3.6 o superior
- No requiere librer√≠as externas

### Instalaci√≥n y Ejecuci√≥n

1. **Guardar el c√≥digo** en un archivo `triqui_minimax.py`

2. **Ejecutar desde la terminal:**
```bash
python triqui_minimax.py
```

3. **Interacci√≥n con el juego:**
   - Elegir qui√©n empieza (1: Humano, 2: IA)
   - Ingresar coordenadas para tu movimiento (fila y columna de 0 a 2)
   - La IA calcular√° autom√°ticamente su mejor jugada

### Ejemplo de Partida

```
BIENVENIDO AL JUEGO DE TRIQUI CON MINIMAX
==========================================

¬øQui√©n empieza? (1: Humano, 2: IA): 1

  0   1   2
0   |   |  
  ---------
1   |   |  
  ---------
2   |   |  

Tu turno (X)
Ingresa la fila (0-2): 1
Ingresa la columna (0-2): 1

  0   1   2
0   |   |  
  ---------
1   | X |  
  ---------
2   |   |  

Turno de la IA (O)...
La IA juega en (0, 0)

  0   1   2
0 O |   |  
  ---------
1   | X |  
  ---------
2   |   |  
```

---

## üîç An√°lisis de Complejidad

### Complejidad Temporal

- **Sin poda**: O(b^d) donde b = factor de ramificaci√≥n, d = profundidad
  - Peor caso Triqui: O(9!) = O(362,880) nodos
  
- **Con poda Alfa-Beta**: O(b^(d/2)) en el mejor caso
  - Mejor caso Triqui: O(‚àö(9!)) ‚âà O(602) nodos

### Complejidad Espacial

- O(d) para la pila de recursi√≥n
- En Triqui: O(9) m√°ximo

---

## üìä Validaci√≥n y Pruebas

### Casos de Prueba Implementados

1. **Victoria del Jugador X (Horizontal)**
```
X | X | X
---------
O | O |  
---------
  |   |  
```

2. **Victoria del Jugador O (Vertical)**
```
X | O | X
---------
  | O | X
---------
  | O |  
```

3. **Victoria Diagonal**
```
X | O | O
---------
  | X |  
---------
O |   | X
```

4. **Empate**
```
X | O | X
---------
X | X | O
---------
O | X | O
```

### Garant√≠as del Algoritmo

- ‚úÖ La IA **nunca pierde** contra un jugador humano
- ‚úÖ Encuentra la **jugada √≥ptima** en cada turno
- ‚úÖ **Bloquea** amenazas del oponente
- ‚úÖ **Aprovecha** oportunidades de victoria

---

## üìà Posibles Mejoras Futuras

1. **Interfaz Gr√°fica**: Implementar GUI con tkinter o pygame
2. **Diferentes Niveles de Dificultad**: Limitar profundidad de b√∫squeda
3. **Aprendizaje por Refuerzo**: Implementar Q-Learning
4. **Tableros M√°s Grandes**: Extender a 4x4 o 5x5
5. **Base de Datos de Aperturas**: Memorizar jugadas iniciales √≥ptimas

---

## üìù Conclusiones

Esta implementaci√≥n del algoritmo MINIMAX para Triqui demuestra:

1. **Correcta representaci√≥n del espacio de estados** mediante estructura de datos eficiente
2. **Funci√≥n heur√≠stica robusta** que eval√∫a correctamente las posiciones
3. **Generaci√≥n completa de sucesores** para exploraci√≥n exhaustiva
4. **Sistema de turnos funcional** con validaci√≥n de entradas
5. **Optimizaci√≥n mediante poda Alfa-Beta** reduciendo el espacio de b√∫squeda

El algoritmo garantiza juego √≥ptimo por parte de la IA, siendo imposible ganarle si juega correctamente, demostrando as√≠ la efectividad del enfoque MINIMAX en juegos de suma cero con informaci√≥n perfecta.

---

## üìö Referencias

- Russell, S. & Norvig, P. (2020). *Artificial Intelligence: A Modern Approach* (4th ed.)
- Algoritmo Minimax - Stanford CS221
- Alpha-Beta Pruning - MIT OpenCourseWare

---

**Fecha de Entrega**: [Pr√≥xima clase]  
**Versi√≥n**: 1.0